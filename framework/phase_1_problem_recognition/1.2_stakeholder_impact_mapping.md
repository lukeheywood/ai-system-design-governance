# 1.2 Stakeholder Impact Mapping

AI governance failures do not affect all actors equally.

One of the defining characteristics of poorly governed AI systems is a **misalignment between authority, benefit, and burden**. This section maps the primary stakeholder groups involved in AI-enabled systems and clarifies how risk, responsibility, and power are currently distributed â€” with specific attention to the Australian enterprise and public-sector context.

This mapping is descriptive, not normative. It is intended to surface structural imbalances before controls or remedies are proposed.

---

## 1.2.1 Australian Public Servants

**Typical role**

* Operate, administer, or rely on AI-enabled systems
* Implement policy through automated or semi-automated decision processes
* Interface directly with affected individuals and communities

**Observed impact**

* Carry frontline responsibility for outcomes they do not control
* Are required to trust system outputs they cannot fully inspect
* Experience reputational and professional risk when systems fail

**Authority gap**

* Limited ability to pause, override, or reject system behaviour
* Minimal influence over procurement, model selection, or vendor constraints

Public servants are often positioned as the visible face of AI decisions while lacking meaningful authority over the systems that generate them.

---

## 1.2.2 Vendors and Technology Providers

**Typical role**

* Design, build, and maintain AI models and platforms
* Define system capabilities, constraints, and update cycles
* Provide assurances through documentation, metrics, and contractual terms

**Observed impact**

* Capture commercial upside from deployment and scale
* Limit liability through contractual framing and abstraction
* Retain control over system internals and evolution

**Authority concentration**

* Significant influence over what is technically possible
* Ability to frame risk in technical rather than governance terms

Vendors often hold disproportionate power relative to their downstream accountability.

---

## 1.2.3 Executives and Senior Decision-Makers

**Typical role**

* Approve adoption and deployment of AI systems
* Set organisational risk posture and strategic direction
* Delegate operational responsibility downward

**Observed impact**

* Benefit from efficiency and scalability gains
* Are insulated from day-to-day system failures
* Rely on aggregated reporting rather than direct system visibility

**Delegation pattern**

* Authority to deploy is retained
* Responsibility for consequences is diffused

This creates a structural incentive to prioritise deployment speed over governance maturity.

---

## 1.2.4 The Public and Affected Individuals

**Typical role**

* Subject to AI-mediated decisions
* Provide data inputs that systems depend on
* Bear downstream social, economic, or legal consequences

**Observed impact**

* Experience outcomes without visibility into decision logic
* Have limited avenues for appeal or redress
* Absorb harm when systems fail or drift

**Power imbalance**

* Minimal ability to influence system design or operation
* Dependence on institutional governance to act on their behalf

The public carries the highest exposure to harm and the least structural power.

---

## 1.2.5 Cross-Cutting Pattern: Authority vs Burden

Across all stakeholder groups, a consistent pattern emerges:

* Authority tends to sit upstream (design, procurement, deployment)
* Burden accumulates downstream (operation, impact, harm)
* Accountability mechanisms activate late, if at all

This misalignment is the central risk driver addressed by this governance framework.

---

## 1.2.6 Implications for Governance Design

Without explicitly mapping these imbalances:

* Governance controls target the wrong actors
* Risk is managed symbolically rather than structurally
* Enforcement mechanisms fail to activate in time

Effective AI governance must therefore begin by making these stakeholder dynamics explicit before attempting intervention.
